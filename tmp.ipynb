{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do\n",
    "\n",
    "* 綺麗な可視化\n",
    "* 記事にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import linalg_utils\n",
    "importlib.reload(linalg_utils)\n",
    "\n",
    "import misc_utils\n",
    "importlib.reload(misc_utils)\n",
    "\n",
    "import gp_utils\n",
    "importlib.reload(gp_utils)\n",
    "\n",
    "import gp_regression\n",
    "importlib.reload(gp_regression)\n",
    "from gp_regression import GP_regression\n",
    "from gp_regression import Sparse_GP_regression_SoR \n",
    "from gp_regression import Sparse_GP_regression_DTC\n",
    "from gp_regression import Sparse_GP_regression_FITC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Latent_Function():\n",
    "    def __init__(self, noise_level=0.1):\n",
    "        self.noise_level = noise_level\n",
    "        self.noise = None\n",
    "\n",
    "    def _f(self, X):\n",
    "        # ここを好きにカスタマイズ\n",
    "        tmp = np.sin(X) + np.cos(X)\n",
    "        return tmp\n",
    "    \n",
    "    def f(self, X, observed=False):\n",
    "        tmp = self._f(X)\n",
    "\n",
    "        if observed is True:\n",
    "            self.noise = np.random.rand(*X.shape) * self.noise_level\n",
    "\n",
    "            if isinstance(X, np.ndarray):\n",
    "                return np.array(tmp) + self.noise\n",
    "            elif isinstance(X, torch.Tensor):\n",
    "                return tmp + torch.Tensor(self.noise)\n",
    "        \n",
    "        else:\n",
    "            if isinstance(X, np.ndarray):\n",
    "                return np.array(tmp)\n",
    "            elif isinstance(X, torch.Tensor):\n",
    "                return tmp\n",
    "\n",
    "\n",
    "def make_data(f, X=None, X_pred=None):\n",
    "    if X is None:\n",
    "        X_normal = torch.randn(50) * 1.5 + 4 \n",
    "        X_normal = torch.clip(X_normal, 0, 10) \n",
    "        X_uniform = torch.rand(50) * 6 + 2  \n",
    "        X_combined = torch.cat([X_normal, X_uniform])\n",
    "        X, _ = torch.sort(X_combined)\n",
    "        X = X.reshape(-1, 1)\n",
    "\n",
    "    y = f(X, observed=True)\n",
    "\n",
    "    if X_pred is None:\n",
    "        X_max, X_min = X.max(), X.min()\n",
    "        interval = torch.abs(X_max - X_min)\n",
    "        size = int(torch.ceil(interval / 0.1))\n",
    "        X_pred_max, X_pred_min = X_max + interval * 0.2, X_min - interval * 0.2\n",
    "        X_pred = torch.linspace(X_pred_min, X_pred_max, size).reshape(-1, 1)\n",
    "\n",
    "    return X, y, X_pred\n",
    "\n",
    "\n",
    "def visualize(X_pred, f, mean, cov, p_inputs=None, title=\"\"):\n",
    "    mean = mean.ravel().detach().numpy()\n",
    "    var = torch.diagonal(cov).detach().numpy()\n",
    "    X_pred = X_pred.ravel().detach().numpy()\n",
    "\n",
    "    if p_inputs is not None:\n",
    "        p_inputs = p_inputs.ravel().detach().numpy()\n",
    "\n",
    "    credible_interval = 1.96 * np.sqrt(var) # 95%\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=X_pred, y=f(X_pred), line_color=\"#00CC00\", name=\"Latent Function\"))\n",
    "    fig.add_trace(go.Scatter(x=X_pred, y=mean, line_color=\"#FE73FF\", name=\"Mean\"))\n",
    "    fig.add_trace(go.Scatter(x=X_pred, y=mean-credible_interval, mode='lines', line=dict(color='lightgray'), showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=X_pred, y=mean+credible_interval, mode='lines', line=dict(color='lightgray'), fill='tonexty', showlegend=False))\n",
    "    \n",
    "    if p_inputs is not None:\n",
    "        fig.add_trace(go.Scatter(x=p_inputs, y=f(p_inputs), mode='markers', marker=dict(size=8, color=\"#FF0000\"), name=\"Pseudo-inputs\"))\n",
    "\n",
    "    fig.update_layout(title=title, xaxis_title=\"X\", yaxis_title=\"f*\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Latent_Function(noise_level=0.1).f\n",
    "X, y, X_pred = make_data(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = GP_regression(X, y)\n",
    "mean1, cov1 = model1.predict(X_pred.clone())\n",
    "\n",
    "# visualize(X_pred, f, mean1, cov1, title=\"GP_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_iter: 1/200\n",
      "opt_iter: 2/200\n",
      "opt_iter: 3/200\n",
      "opt_iter: 4/200\n",
      "opt_iter: 5/200\n",
      "opt_iter: 6/200\n",
      "opt_iter: 7/200\n",
      "opt_iter: 8/200\n",
      "opt_iter: 9/200\n",
      "opt_iter: 10/200\n",
      "opt_iter: 11/200\n",
      "opt_iter: 12/200\n",
      "opt_iter: 13/200\n",
      "opt_iter: 14/200\n",
      "opt_iter: 15/200\n",
      "opt_iter: 16/200\n",
      "opt_iter: 17/200\n",
      "opt_iter: 18/200\n",
      "opt_iter: 19/200\n",
      "opt_iter: 20/200\n",
      "opt_iter: 21/200\n",
      "opt_iter: 22/200\n",
      "opt_iter: 23/200\n",
      "opt_iter: 24/200\n",
      "opt_iter: 25/200\n",
      "opt_iter: 26/200\n",
      "opt_iter: 27/200\n",
      "opt_iter: 28/200\n",
      "opt_iter: 29/200\n",
      "opt_iter: 30/200\n",
      "opt_iter: 31/200\n",
      "opt_iter: 32/200\n",
      "opt_iter: 33/200\n",
      "opt_iter: 34/200\n",
      "opt_iter: 35/200\n",
      "opt_iter: 36/200\n",
      "opt_iter: 37/200\n",
      "opt_iter: 38/200\n",
      "opt_iter: 39/200\n",
      "opt_iter: 40/200\n",
      "opt_iter: 41/200\n",
      "opt_iter: 42/200\n",
      "opt_iter: 43/200\n",
      "opt_iter: 44/200\n",
      "opt_iter: 45/200\n",
      "opt_iter: 46/200\n",
      "opt_iter: 47/200\n",
      "opt_iter: 48/200\n",
      "opt_iter: 49/200\n",
      "opt_iter: 50/200\n",
      "opt_iter: 51/200\n",
      "opt_iter: 52/200\n",
      "opt_iter: 53/200\n",
      "opt_iter: 54/200\n",
      "opt_iter: 55/200\n",
      "opt_iter: 56/200\n",
      "opt_iter: 57/200\n",
      "opt_iter: 58/200\n",
      "opt_iter: 59/200\n",
      "opt_iter: 60/200\n",
      "opt_iter: 61/200\n",
      "opt_iter: 62/200\n",
      "opt_iter: 63/200\n",
      "opt_iter: 64/200\n",
      "opt_iter: 65/200\n",
      "opt_iter: 66/200\n",
      "opt_iter: 67/200\n",
      "opt_iter: 68/200\n",
      "opt_iter: 69/200\n",
      "opt_iter: 70/200\n",
      "opt_iter: 71/200\n",
      "opt_iter: 72/200\n",
      "opt_iter: 73/200\n",
      "opt_iter: 74/200\n",
      "opt_iter: 75/200\n",
      "opt_iter: 76/200\n",
      "opt_iter: 77/200\n",
      "opt_iter: 78/200\n",
      "opt_iter: 79/200\n",
      "opt_iter: 80/200\n",
      "opt_iter: 81/200\n",
      "opt_iter: 82/200\n",
      "opt_iter: 83/200\n",
      "opt_iter: 84/200\n",
      "opt_iter: 85/200\n",
      "opt_iter: 86/200\n",
      "opt_iter: 87/200\n",
      "opt_iter: 88/200\n",
      "opt_iter: 89/200\n",
      "opt_iter: 90/200\n",
      "opt_iter: 91/200\n",
      "opt_iter: 92/200\n",
      "opt_iter: 93/200\n",
      "opt_iter: 94/200\n",
      "opt_iter: 95/200\n",
      "opt_iter: 96/200\n",
      "opt_iter: 97/200\n",
      "opt_iter: 98/200\n",
      "opt_iter: 99/200\n",
      "opt_iter: 100/200\n",
      "opt_iter: 101/200\n",
      "opt_iter: 102/200\n",
      "opt_iter: 103/200\n",
      "opt_iter: 104/200\n",
      "opt_iter: 105/200\n",
      "opt_iter: 106/200\n",
      "opt_iter: 107/200\n",
      "opt_iter: 108/200\n",
      "opt_iter: 109/200\n",
      "opt_iter: 110/200\n",
      "opt_iter: 111/200\n",
      "opt_iter: 112/200\n",
      "opt_iter: 113/200\n",
      "opt_iter: 114/200\n",
      "opt_iter: 115/200\n",
      "opt_iter: 116/200\n",
      "opt_iter: 117/200\n",
      "opt_iter: 118/200\n",
      "opt_iter: 119/200\n",
      "opt_iter: 120/200\n",
      "opt_iter: 121/200\n",
      "opt_iter: 122/200\n",
      "opt_iter: 123/200\n",
      "opt_iter: 124/200\n",
      "opt_iter: 125/200\n",
      "opt_iter: 126/200\n",
      "opt_iter: 127/200\n",
      "opt_iter: 128/200\n",
      "opt_iter: 129/200\n",
      "opt_iter: 130/200\n",
      "opt_iter: 131/200\n",
      "opt_iter: 132/200\n",
      "opt_iter: 133/200\n",
      "opt_iter: 134/200\n",
      "opt_iter: 135/200\n",
      "opt_iter: 136/200\n",
      "opt_iter: 137/200\n",
      "opt_iter: 138/200\n",
      "opt_iter: 139/200\n",
      "opt_iter: 140/200\n",
      "opt_iter: 141/200\n",
      "opt_iter: 142/200\n",
      "opt_iter: 143/200\n",
      "opt_iter: 144/200\n",
      "opt_iter: 145/200\n",
      "opt_iter: 146/200\n",
      "opt_iter: 147/200\n",
      "opt_iter: 148/200\n",
      "opt_iter: 149/200\n",
      "opt_iter: 150/200\n",
      "opt_iter: 151/200\n",
      "opt_iter: 152/200\n",
      "opt_iter: 153/200\n",
      "opt_iter: 154/200\n",
      "opt_iter: 155/200\n",
      "opt_iter: 156/200\n",
      "opt_iter: 157/200\n",
      "opt_iter: 158/200\n",
      "opt_iter: 159/200\n",
      "opt_iter: 160/200\n",
      "opt_iter: 161/200\n",
      "opt_iter: 162/200\n",
      "opt_iter: 163/200\n",
      "opt_iter: 164/200\n",
      "opt_iter: 165/200\n",
      "opt_iter: 166/200\n",
      "opt_iter: 167/200\n",
      "opt_iter: 168/200\n",
      "opt_iter: 169/200\n",
      "opt_iter: 170/200\n",
      "opt_iter: 171/200\n",
      "opt_iter: 172/200\n",
      "opt_iter: 173/200\n",
      "opt_iter: 174/200\n",
      "opt_iter: 175/200\n",
      "opt_iter: 176/200\n",
      "opt_iter: 177/200\n",
      "opt_iter: 178/200\n",
      "opt_iter: 179/200\n",
      "opt_iter: 180/200\n",
      "opt_iter: 181/200\n",
      "opt_iter: 182/200\n",
      "opt_iter: 183/200\n",
      "opt_iter: 184/200\n",
      "opt_iter: 185/200\n",
      "opt_iter: 186/200\n",
      "opt_iter: 187/200\n",
      "opt_iter: 188/200\n",
      "opt_iter: 189/200\n",
      "opt_iter: 190/200\n",
      "opt_iter: 191/200\n",
      "opt_iter: 192/200\n",
      "opt_iter: 193/200\n",
      "opt_iter: 194/200\n",
      "opt_iter: 195/200\n",
      "opt_iter: 196/200\n",
      "opt_iter: 197/200\n",
      "opt_iter: 198/200\n",
      "opt_iter: 199/200\n",
      "opt_iter: 200/200\n"
     ]
    }
   ],
   "source": [
    "model1.optimize(iteration=200, learning_rate=0.01)\n",
    "mean1_opt, cov1_opt = model1.predict(X_pred.clone())\n",
    "\n",
    "# visualize(X_pred, f, mean1_opt, cov1_opt, title=\"Optimized GP_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise</th>\n",
       "      <th>variance</th>\n",
       "      <th>lengthscale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990050</td>\n",
       "      <td>1.010050</td>\n",
       "      <td>0.505025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980196</td>\n",
       "      <td>1.020198</td>\n",
       "      <td>0.510098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970437</td>\n",
       "      <td>1.030442</td>\n",
       "      <td>0.515217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.960769</td>\n",
       "      <td>1.040782</td>\n",
       "      <td>0.520380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.051696</td>\n",
       "      <td>4.073686</td>\n",
       "      <td>0.943412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.050539</td>\n",
       "      <td>4.094551</td>\n",
       "      <td>0.942738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.049404</td>\n",
       "      <td>4.115468</td>\n",
       "      <td>0.942022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.048290</td>\n",
       "      <td>4.136438</td>\n",
       "      <td>0.941262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.047197</td>\n",
       "      <td>4.157461</td>\n",
       "      <td>0.940457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        noise  variance  lengthscale\n",
       "0    1.000000  1.000000     0.500000\n",
       "1    0.990050  1.010050     0.505025\n",
       "2    0.980196  1.020198     0.510098\n",
       "3    0.970437  1.030442     0.515217\n",
       "4    0.960769  1.040782     0.520380\n",
       "..        ...       ...          ...\n",
       "196  0.051696  4.073686     0.943412\n",
       "197  0.050539  4.094551     0.942738\n",
       "198  0.049404  4.115468     0.942022\n",
       "199  0.048290  4.136438     0.941262\n",
       "200  0.047197  4.157461     0.940457\n",
       "\n",
       "[201 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.make_params_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sparse_GP_regression_SoR(X, y, p_optimized=True)\n",
    "mean2, cov2 = model2.predict(X_pred.clone())\n",
    "\n",
    "# visualize(X_pred, f, mean2, cov2, p_inputs=model2.pseudo_inputs, title=\"SoR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_iter: 1/200\n",
      "opt_iter: 2/200\n",
      "opt_iter: 3/200\n",
      "opt_iter: 4/200\n",
      "opt_iter: 5/200\n",
      "opt_iter: 6/200\n",
      "opt_iter: 7/200\n",
      "opt_iter: 8/200\n",
      "opt_iter: 9/200\n",
      "opt_iter: 10/200\n",
      "opt_iter: 11/200\n",
      "opt_iter: 12/200\n",
      "opt_iter: 13/200\n",
      "opt_iter: 14/200\n",
      "opt_iter: 15/200\n",
      "opt_iter: 16/200\n",
      "opt_iter: 17/200\n",
      "opt_iter: 18/200\n",
      "opt_iter: 19/200\n",
      "opt_iter: 20/200\n",
      "opt_iter: 21/200\n",
      "opt_iter: 22/200\n",
      "opt_iter: 23/200\n",
      "opt_iter: 24/200\n",
      "opt_iter: 25/200\n",
      "opt_iter: 26/200\n",
      "opt_iter: 27/200\n",
      "opt_iter: 28/200\n",
      "opt_iter: 29/200\n",
      "opt_iter: 30/200\n",
      "opt_iter: 31/200\n",
      "opt_iter: 32/200\n",
      "opt_iter: 33/200\n",
      "opt_iter: 34/200\n",
      "opt_iter: 35/200\n",
      "opt_iter: 36/200\n",
      "opt_iter: 37/200\n",
      "opt_iter: 38/200\n",
      "opt_iter: 39/200\n",
      "opt_iter: 40/200\n",
      "opt_iter: 41/200\n",
      "opt_iter: 42/200\n",
      "opt_iter: 43/200\n",
      "opt_iter: 44/200\n",
      "opt_iter: 45/200\n",
      "opt_iter: 46/200\n",
      "opt_iter: 47/200\n",
      "opt_iter: 48/200\n",
      "opt_iter: 49/200\n",
      "opt_iter: 50/200\n",
      "opt_iter: 51/200\n",
      "opt_iter: 52/200\n",
      "opt_iter: 53/200\n",
      "opt_iter: 54/200\n",
      "opt_iter: 55/200\n",
      "opt_iter: 56/200\n",
      "opt_iter: 57/200\n",
      "opt_iter: 58/200\n",
      "opt_iter: 59/200\n",
      "opt_iter: 60/200\n",
      "opt_iter: 61/200\n",
      "opt_iter: 62/200\n",
      "opt_iter: 63/200\n",
      "opt_iter: 64/200\n",
      "opt_iter: 65/200\n",
      "opt_iter: 66/200\n",
      "opt_iter: 67/200\n",
      "opt_iter: 68/200\n",
      "opt_iter: 69/200\n",
      "opt_iter: 70/200\n",
      "opt_iter: 71/200\n",
      "opt_iter: 72/200\n",
      "opt_iter: 73/200\n",
      "opt_iter: 74/200\n",
      "opt_iter: 75/200\n",
      "opt_iter: 76/200\n",
      "opt_iter: 77/200\n",
      "opt_iter: 78/200\n",
      "opt_iter: 79/200\n",
      "opt_iter: 80/200\n",
      "opt_iter: 81/200\n",
      "opt_iter: 82/200\n",
      "opt_iter: 83/200\n",
      "opt_iter: 84/200\n",
      "opt_iter: 85/200\n",
      "opt_iter: 86/200\n",
      "opt_iter: 87/200\n",
      "opt_iter: 88/200\n",
      "opt_iter: 89/200\n",
      "opt_iter: 90/200\n",
      "opt_iter: 91/200\n",
      "opt_iter: 92/200\n",
      "opt_iter: 93/200\n",
      "opt_iter: 94/200\n",
      "opt_iter: 95/200\n",
      "opt_iter: 96/200\n",
      "opt_iter: 97/200\n",
      "opt_iter: 98/200\n",
      "opt_iter: 99/200\n",
      "opt_iter: 100/200\n",
      "opt_iter: 101/200\n",
      "opt_iter: 102/200\n",
      "opt_iter: 103/200\n",
      "opt_iter: 104/200\n",
      "opt_iter: 105/200\n",
      "opt_iter: 106/200\n",
      "opt_iter: 107/200\n",
      "opt_iter: 108/200\n",
      "opt_iter: 109/200\n",
      "opt_iter: 110/200\n",
      "opt_iter: 111/200\n",
      "opt_iter: 112/200\n",
      "opt_iter: 113/200\n",
      "opt_iter: 114/200\n",
      "opt_iter: 115/200\n",
      "opt_iter: 116/200\n",
      "opt_iter: 117/200\n",
      "opt_iter: 118/200\n",
      "opt_iter: 119/200\n",
      "opt_iter: 120/200\n",
      "opt_iter: 121/200\n",
      "opt_iter: 122/200\n",
      "opt_iter: 123/200\n",
      "opt_iter: 124/200\n",
      "opt_iter: 125/200\n",
      "opt_iter: 126/200\n",
      "opt_iter: 127/200\n",
      "opt_iter: 128/200\n",
      "opt_iter: 129/200\n",
      "opt_iter: 130/200\n",
      "opt_iter: 131/200\n",
      "opt_iter: 132/200\n",
      "opt_iter: 133/200\n",
      "opt_iter: 134/200\n",
      "opt_iter: 135/200\n",
      "opt_iter: 136/200\n",
      "opt_iter: 137/200\n",
      "opt_iter: 138/200\n",
      "opt_iter: 139/200\n",
      "opt_iter: 140/200\n",
      "opt_iter: 141/200\n",
      "opt_iter: 142/200\n",
      "opt_iter: 143/200\n",
      "opt_iter: 144/200\n",
      "opt_iter: 145/200\n",
      "opt_iter: 146/200\n",
      "opt_iter: 147/200\n",
      "opt_iter: 148/200\n",
      "opt_iter: 149/200\n",
      "opt_iter: 150/200\n",
      "opt_iter: 151/200\n",
      "opt_iter: 152/200\n",
      "opt_iter: 153/200\n",
      "opt_iter: 154/200\n",
      "opt_iter: 155/200\n",
      "opt_iter: 156/200\n",
      "opt_iter: 157/200\n",
      "opt_iter: 158/200\n",
      "opt_iter: 159/200\n",
      "opt_iter: 160/200\n",
      "opt_iter: 161/200\n",
      "opt_iter: 162/200\n",
      "opt_iter: 163/200\n",
      "opt_iter: 164/200\n",
      "opt_iter: 165/200\n",
      "opt_iter: 166/200\n",
      "opt_iter: 167/200\n",
      "opt_iter: 168/200\n",
      "opt_iter: 169/200\n",
      "opt_iter: 170/200\n",
      "opt_iter: 171/200\n",
      "opt_iter: 172/200\n",
      "opt_iter: 173/200\n",
      "opt_iter: 174/200\n",
      "opt_iter: 175/200\n",
      "opt_iter: 176/200\n",
      "opt_iter: 177/200\n",
      "opt_iter: 178/200\n",
      "opt_iter: 179/200\n",
      "opt_iter: 180/200\n",
      "opt_iter: 181/200\n",
      "opt_iter: 182/200\n",
      "opt_iter: 183/200\n",
      "opt_iter: 184/200\n",
      "opt_iter: 185/200\n",
      "opt_iter: 186/200\n",
      "opt_iter: 187/200\n",
      "opt_iter: 188/200\n",
      "opt_iter: 189/200\n",
      "opt_iter: 190/200\n",
      "opt_iter: 191/200\n",
      "opt_iter: 192/200\n",
      "opt_iter: 193/200\n",
      "opt_iter: 194/200\n",
      "opt_iter: 195/200\n",
      "opt_iter: 196/200\n",
      "opt_iter: 197/200\n",
      "opt_iter: 198/200\n",
      "opt_iter: 199/200\n",
      "opt_iter: 200/200\n"
     ]
    }
   ],
   "source": [
    "model2.optimize(iteration=200, learning_rate=0.01)\n",
    "mean2_opt, cov2_opt = model2.predict(X_pred.clone())\n",
    "\n",
    "# visualize(X_pred, f, mean2_opt, cov2_opt, p_inputs=model2.pseudo_inputs, title=\"Optimized SoR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise</th>\n",
       "      <th>variance</th>\n",
       "      <th>lengthscale</th>\n",
       "      <th>u_1</th>\n",
       "      <th>u_2</th>\n",
       "      <th>u_3</th>\n",
       "      <th>u_4</th>\n",
       "      <th>u_5</th>\n",
       "      <th>u_6</th>\n",
       "      <th>u_7</th>\n",
       "      <th>u_8</th>\n",
       "      <th>u_9</th>\n",
       "      <th>u_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>1.774372</td>\n",
       "      <td>2.549012</td>\n",
       "      <td>3.323653</td>\n",
       "      <td>4.098293</td>\n",
       "      <td>4.872934</td>\n",
       "      <td>5.647574</td>\n",
       "      <td>6.422214</td>\n",
       "      <td>7.196855</td>\n",
       "      <td>7.971495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990050</td>\n",
       "      <td>1.010050</td>\n",
       "      <td>0.505025</td>\n",
       "      <td>1.009731</td>\n",
       "      <td>1.784372</td>\n",
       "      <td>2.559012</td>\n",
       "      <td>3.313653</td>\n",
       "      <td>4.108293</td>\n",
       "      <td>4.862934</td>\n",
       "      <td>5.637574</td>\n",
       "      <td>6.432214</td>\n",
       "      <td>7.186855</td>\n",
       "      <td>7.961495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980194</td>\n",
       "      <td>1.020200</td>\n",
       "      <td>0.510065</td>\n",
       "      <td>1.019704</td>\n",
       "      <td>1.794339</td>\n",
       "      <td>2.568933</td>\n",
       "      <td>3.314649</td>\n",
       "      <td>4.116527</td>\n",
       "      <td>4.853544</td>\n",
       "      <td>5.627633</td>\n",
       "      <td>6.440354</td>\n",
       "      <td>7.177133</td>\n",
       "      <td>7.951505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970430</td>\n",
       "      <td>1.030450</td>\n",
       "      <td>0.515095</td>\n",
       "      <td>1.029613</td>\n",
       "      <td>1.804274</td>\n",
       "      <td>2.578772</td>\n",
       "      <td>3.320132</td>\n",
       "      <td>4.121724</td>\n",
       "      <td>4.845182</td>\n",
       "      <td>5.617785</td>\n",
       "      <td>6.444156</td>\n",
       "      <td>7.167861</td>\n",
       "      <td>7.941534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.960753</td>\n",
       "      <td>1.040801</td>\n",
       "      <td>0.520083</td>\n",
       "      <td>1.039410</td>\n",
       "      <td>1.814179</td>\n",
       "      <td>2.588522</td>\n",
       "      <td>3.327286</td>\n",
       "      <td>4.123969</td>\n",
       "      <td>4.838044</td>\n",
       "      <td>5.608054</td>\n",
       "      <td>6.443541</td>\n",
       "      <td>7.159102</td>\n",
       "      <td>7.931596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.042544</td>\n",
       "      <td>6.454843</td>\n",
       "      <td>0.447061</td>\n",
       "      <td>1.061071</td>\n",
       "      <td>1.987326</td>\n",
       "      <td>2.620075</td>\n",
       "      <td>3.333212</td>\n",
       "      <td>4.010362</td>\n",
       "      <td>4.653823</td>\n",
       "      <td>5.267927</td>\n",
       "      <td>6.167223</td>\n",
       "      <td>6.917839</td>\n",
       "      <td>7.707902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.041558</td>\n",
       "      <td>6.512527</td>\n",
       "      <td>0.447141</td>\n",
       "      <td>1.061186</td>\n",
       "      <td>1.985551</td>\n",
       "      <td>2.619605</td>\n",
       "      <td>3.333238</td>\n",
       "      <td>4.010471</td>\n",
       "      <td>4.655941</td>\n",
       "      <td>5.268230</td>\n",
       "      <td>6.167650</td>\n",
       "      <td>6.920149</td>\n",
       "      <td>7.707936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.040591</td>\n",
       "      <td>6.570703</td>\n",
       "      <td>0.447395</td>\n",
       "      <td>1.063178</td>\n",
       "      <td>1.982501</td>\n",
       "      <td>2.617110</td>\n",
       "      <td>3.335722</td>\n",
       "      <td>4.008265</td>\n",
       "      <td>4.659973</td>\n",
       "      <td>5.267832</td>\n",
       "      <td>6.166779</td>\n",
       "      <td>6.923382</td>\n",
       "      <td>7.707485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.039644</td>\n",
       "      <td>6.629376</td>\n",
       "      <td>0.447289</td>\n",
       "      <td>1.061463</td>\n",
       "      <td>1.981761</td>\n",
       "      <td>2.617614</td>\n",
       "      <td>3.334538</td>\n",
       "      <td>4.009846</td>\n",
       "      <td>4.660091</td>\n",
       "      <td>5.268501</td>\n",
       "      <td>6.169617</td>\n",
       "      <td>6.922688</td>\n",
       "      <td>7.709701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.038716</td>\n",
       "      <td>6.688550</td>\n",
       "      <td>0.447089</td>\n",
       "      <td>1.058743</td>\n",
       "      <td>1.981638</td>\n",
       "      <td>2.618797</td>\n",
       "      <td>3.332595</td>\n",
       "      <td>4.012104</td>\n",
       "      <td>4.659637</td>\n",
       "      <td>5.269165</td>\n",
       "      <td>6.172334</td>\n",
       "      <td>6.922341</td>\n",
       "      <td>7.711478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        noise  variance  lengthscale       u_1       u_2       u_3       u_4  \\\n",
       "0    1.000000  1.000000     0.500000  0.999731  1.774372  2.549012  3.323653   \n",
       "1    0.990050  1.010050     0.505025  1.009731  1.784372  2.559012  3.313653   \n",
       "2    0.980194  1.020200     0.510065  1.019704  1.794339  2.568933  3.314649   \n",
       "3    0.970430  1.030450     0.515095  1.029613  1.804274  2.578772  3.320132   \n",
       "4    0.960753  1.040801     0.520083  1.039410  1.814179  2.588522  3.327286   \n",
       "..        ...       ...          ...       ...       ...       ...       ...   \n",
       "196  0.042544  6.454843     0.447061  1.061071  1.987326  2.620075  3.333212   \n",
       "197  0.041558  6.512527     0.447141  1.061186  1.985551  2.619605  3.333238   \n",
       "198  0.040591  6.570703     0.447395  1.063178  1.982501  2.617110  3.335722   \n",
       "199  0.039644  6.629376     0.447289  1.061463  1.981761  2.617614  3.334538   \n",
       "200  0.038716  6.688550     0.447089  1.058743  1.981638  2.618797  3.332595   \n",
       "\n",
       "          u_5       u_6       u_7       u_8       u_9      u_10  \n",
       "0    4.098293  4.872934  5.647574  6.422214  7.196855  7.971495  \n",
       "1    4.108293  4.862934  5.637574  6.432214  7.186855  7.961495  \n",
       "2    4.116527  4.853544  5.627633  6.440354  7.177133  7.951505  \n",
       "3    4.121724  4.845182  5.617785  6.444156  7.167861  7.941534  \n",
       "4    4.123969  4.838044  5.608054  6.443541  7.159102  7.931596  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "196  4.010362  4.653823  5.267927  6.167223  6.917839  7.707902  \n",
       "197  4.010471  4.655941  5.268230  6.167650  6.920149  7.707936  \n",
       "198  4.008265  4.659973  5.267832  6.166779  6.923382  7.707485  \n",
       "199  4.009846  4.660091  5.268501  6.169617  6.922688  7.709701  \n",
       "200  4.012104  4.659637  5.269165  6.172334  6.922341  7.711478  \n",
       "\n",
       "[201 rows x 13 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.make_params_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sparse_GP_regression_DTC(X, y, p_optimized=True)\n",
    "mean3, cov3 = model3.predict(X_pred.clone())\n",
    "\n",
    "# visualize(X_pred, f, mean3, cov3, p_inputs=model3.pseudo_inputs, title=\"DTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_iter: 1/200\n",
      "opt_iter: 2/200\n",
      "opt_iter: 3/200\n",
      "opt_iter: 4/200\n",
      "opt_iter: 5/200\n",
      "opt_iter: 6/200\n",
      "opt_iter: 7/200\n",
      "opt_iter: 8/200\n",
      "opt_iter: 9/200\n",
      "opt_iter: 10/200\n",
      "opt_iter: 11/200\n",
      "opt_iter: 12/200\n",
      "opt_iter: 13/200\n",
      "opt_iter: 14/200\n",
      "opt_iter: 15/200\n",
      "opt_iter: 16/200\n",
      "opt_iter: 17/200\n",
      "opt_iter: 18/200\n",
      "opt_iter: 19/200\n",
      "opt_iter: 20/200\n",
      "opt_iter: 21/200\n",
      "opt_iter: 22/200\n",
      "opt_iter: 23/200\n",
      "opt_iter: 24/200\n",
      "opt_iter: 25/200\n",
      "opt_iter: 26/200\n",
      "opt_iter: 27/200\n",
      "opt_iter: 28/200\n",
      "opt_iter: 29/200\n",
      "opt_iter: 30/200\n",
      "opt_iter: 31/200\n",
      "opt_iter: 32/200\n",
      "opt_iter: 33/200\n",
      "opt_iter: 34/200\n",
      "opt_iter: 35/200\n",
      "opt_iter: 36/200\n",
      "opt_iter: 37/200\n",
      "opt_iter: 38/200\n",
      "opt_iter: 39/200\n",
      "opt_iter: 40/200\n",
      "opt_iter: 41/200\n",
      "opt_iter: 42/200\n",
      "opt_iter: 43/200\n",
      "opt_iter: 44/200\n",
      "opt_iter: 45/200\n",
      "opt_iter: 46/200\n",
      "opt_iter: 47/200\n",
      "opt_iter: 48/200\n",
      "opt_iter: 49/200\n",
      "opt_iter: 50/200\n",
      "opt_iter: 51/200\n",
      "opt_iter: 52/200\n",
      "opt_iter: 53/200\n",
      "opt_iter: 54/200\n",
      "opt_iter: 55/200\n",
      "opt_iter: 56/200\n",
      "opt_iter: 57/200\n",
      "opt_iter: 58/200\n",
      "opt_iter: 59/200\n",
      "opt_iter: 60/200\n",
      "opt_iter: 61/200\n",
      "opt_iter: 62/200\n",
      "opt_iter: 63/200\n",
      "opt_iter: 64/200\n",
      "opt_iter: 65/200\n",
      "opt_iter: 66/200\n",
      "opt_iter: 67/200\n",
      "opt_iter: 68/200\n",
      "opt_iter: 69/200\n",
      "opt_iter: 70/200\n",
      "opt_iter: 71/200\n",
      "opt_iter: 72/200\n",
      "opt_iter: 73/200\n",
      "opt_iter: 74/200\n",
      "opt_iter: 75/200\n",
      "opt_iter: 76/200\n",
      "opt_iter: 77/200\n",
      "opt_iter: 78/200\n",
      "opt_iter: 79/200\n",
      "opt_iter: 80/200\n",
      "opt_iter: 81/200\n",
      "opt_iter: 82/200\n",
      "opt_iter: 83/200\n",
      "opt_iter: 84/200\n",
      "opt_iter: 85/200\n",
      "opt_iter: 86/200\n",
      "opt_iter: 87/200\n",
      "opt_iter: 88/200\n",
      "opt_iter: 89/200\n",
      "opt_iter: 90/200\n",
      "opt_iter: 91/200\n",
      "opt_iter: 92/200\n",
      "opt_iter: 93/200\n",
      "opt_iter: 94/200\n",
      "opt_iter: 95/200\n",
      "opt_iter: 96/200\n",
      "opt_iter: 97/200\n",
      "opt_iter: 98/200\n",
      "opt_iter: 99/200\n",
      "opt_iter: 100/200\n",
      "opt_iter: 101/200\n",
      "opt_iter: 102/200\n",
      "opt_iter: 103/200\n",
      "opt_iter: 104/200\n",
      "opt_iter: 105/200\n",
      "opt_iter: 106/200\n",
      "opt_iter: 107/200\n",
      "opt_iter: 108/200\n",
      "opt_iter: 109/200\n",
      "opt_iter: 110/200\n",
      "opt_iter: 111/200\n",
      "opt_iter: 112/200\n",
      "opt_iter: 113/200\n",
      "opt_iter: 114/200\n",
      "opt_iter: 115/200\n",
      "opt_iter: 116/200\n",
      "opt_iter: 117/200\n",
      "opt_iter: 118/200\n",
      "opt_iter: 119/200\n",
      "opt_iter: 120/200\n",
      "opt_iter: 121/200\n",
      "opt_iter: 122/200\n",
      "opt_iter: 123/200\n",
      "opt_iter: 124/200\n",
      "opt_iter: 125/200\n",
      "opt_iter: 126/200\n",
      "opt_iter: 127/200\n",
      "opt_iter: 128/200\n",
      "opt_iter: 129/200\n",
      "opt_iter: 130/200\n",
      "opt_iter: 131/200\n",
      "opt_iter: 132/200\n",
      "opt_iter: 133/200\n",
      "opt_iter: 134/200\n",
      "opt_iter: 135/200\n",
      "opt_iter: 136/200\n",
      "opt_iter: 137/200\n",
      "opt_iter: 138/200\n",
      "opt_iter: 139/200\n",
      "opt_iter: 140/200\n",
      "opt_iter: 141/200\n",
      "opt_iter: 142/200\n",
      "opt_iter: 143/200\n",
      "opt_iter: 144/200\n",
      "opt_iter: 145/200\n",
      "opt_iter: 146/200\n",
      "opt_iter: 147/200\n",
      "opt_iter: 148/200\n",
      "opt_iter: 149/200\n",
      "opt_iter: 150/200\n",
      "opt_iter: 151/200\n",
      "opt_iter: 152/200\n",
      "opt_iter: 153/200\n",
      "opt_iter: 154/200\n",
      "opt_iter: 155/200\n",
      "opt_iter: 156/200\n",
      "opt_iter: 157/200\n",
      "opt_iter: 158/200\n",
      "opt_iter: 159/200\n",
      "opt_iter: 160/200\n",
      "opt_iter: 161/200\n",
      "opt_iter: 162/200\n",
      "opt_iter: 163/200\n",
      "opt_iter: 164/200\n",
      "opt_iter: 165/200\n",
      "opt_iter: 166/200\n",
      "opt_iter: 167/200\n",
      "opt_iter: 168/200\n",
      "opt_iter: 169/200\n",
      "opt_iter: 170/200\n",
      "opt_iter: 171/200\n",
      "opt_iter: 172/200\n",
      "opt_iter: 173/200\n",
      "opt_iter: 174/200\n",
      "opt_iter: 175/200\n",
      "opt_iter: 176/200\n",
      "opt_iter: 177/200\n",
      "opt_iter: 178/200\n",
      "opt_iter: 179/200\n",
      "opt_iter: 180/200\n",
      "opt_iter: 181/200\n",
      "opt_iter: 182/200\n",
      "opt_iter: 183/200\n",
      "opt_iter: 184/200\n",
      "opt_iter: 185/200\n",
      "opt_iter: 186/200\n",
      "opt_iter: 187/200\n",
      "opt_iter: 188/200\n",
      "opt_iter: 189/200\n",
      "opt_iter: 190/200\n",
      "opt_iter: 191/200\n",
      "opt_iter: 192/200\n",
      "opt_iter: 193/200\n",
      "opt_iter: 194/200\n",
      "opt_iter: 195/200\n",
      "opt_iter: 196/200\n",
      "opt_iter: 197/200\n",
      "opt_iter: 198/200\n",
      "opt_iter: 199/200\n",
      "opt_iter: 200/200\n"
     ]
    }
   ],
   "source": [
    "model3.optimize(iteration=200, learning_rate=0.01)\n",
    "mean3_opt, cov3_opt = model3.predict(X_pred.clone())\n",
    "\n",
    "# visualize(X_pred, f, mean3_opt, cov3_opt, p_inputs=model3.pseudo_inputs, title=\"Optimized DTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise</th>\n",
       "      <th>variance</th>\n",
       "      <th>lengthscale</th>\n",
       "      <th>u_1</th>\n",
       "      <th>u_2</th>\n",
       "      <th>u_3</th>\n",
       "      <th>u_4</th>\n",
       "      <th>u_5</th>\n",
       "      <th>u_6</th>\n",
       "      <th>u_7</th>\n",
       "      <th>u_8</th>\n",
       "      <th>u_9</th>\n",
       "      <th>u_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>1.774372</td>\n",
       "      <td>2.549012</td>\n",
       "      <td>3.323653</td>\n",
       "      <td>4.098293</td>\n",
       "      <td>4.872934</td>\n",
       "      <td>5.647574</td>\n",
       "      <td>6.422214</td>\n",
       "      <td>7.196855</td>\n",
       "      <td>7.971495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990050</td>\n",
       "      <td>1.010050</td>\n",
       "      <td>0.505025</td>\n",
       "      <td>1.009731</td>\n",
       "      <td>1.784372</td>\n",
       "      <td>2.559012</td>\n",
       "      <td>3.313653</td>\n",
       "      <td>4.108293</td>\n",
       "      <td>4.862934</td>\n",
       "      <td>5.637574</td>\n",
       "      <td>6.432214</td>\n",
       "      <td>7.186855</td>\n",
       "      <td>7.961495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980194</td>\n",
       "      <td>1.020200</td>\n",
       "      <td>0.510065</td>\n",
       "      <td>1.019704</td>\n",
       "      <td>1.794339</td>\n",
       "      <td>2.568933</td>\n",
       "      <td>3.314649</td>\n",
       "      <td>4.116527</td>\n",
       "      <td>4.853544</td>\n",
       "      <td>5.627633</td>\n",
       "      <td>6.440354</td>\n",
       "      <td>7.177133</td>\n",
       "      <td>7.951505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970430</td>\n",
       "      <td>1.030450</td>\n",
       "      <td>0.515095</td>\n",
       "      <td>1.029613</td>\n",
       "      <td>1.804274</td>\n",
       "      <td>2.578772</td>\n",
       "      <td>3.320132</td>\n",
       "      <td>4.121724</td>\n",
       "      <td>4.845182</td>\n",
       "      <td>5.617785</td>\n",
       "      <td>6.444156</td>\n",
       "      <td>7.167861</td>\n",
       "      <td>7.941534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.960753</td>\n",
       "      <td>1.040801</td>\n",
       "      <td>0.520083</td>\n",
       "      <td>1.039410</td>\n",
       "      <td>1.814179</td>\n",
       "      <td>2.588522</td>\n",
       "      <td>3.327286</td>\n",
       "      <td>4.123969</td>\n",
       "      <td>4.838044</td>\n",
       "      <td>5.608054</td>\n",
       "      <td>6.443541</td>\n",
       "      <td>7.159102</td>\n",
       "      <td>7.931596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.042544</td>\n",
       "      <td>6.454843</td>\n",
       "      <td>0.447061</td>\n",
       "      <td>1.061071</td>\n",
       "      <td>1.987326</td>\n",
       "      <td>2.620075</td>\n",
       "      <td>3.333212</td>\n",
       "      <td>4.010362</td>\n",
       "      <td>4.653823</td>\n",
       "      <td>5.267927</td>\n",
       "      <td>6.167223</td>\n",
       "      <td>6.917839</td>\n",
       "      <td>7.707902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.041558</td>\n",
       "      <td>6.512527</td>\n",
       "      <td>0.447141</td>\n",
       "      <td>1.061186</td>\n",
       "      <td>1.985551</td>\n",
       "      <td>2.619605</td>\n",
       "      <td>3.333238</td>\n",
       "      <td>4.010471</td>\n",
       "      <td>4.655941</td>\n",
       "      <td>5.268230</td>\n",
       "      <td>6.167650</td>\n",
       "      <td>6.920149</td>\n",
       "      <td>7.707936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.040591</td>\n",
       "      <td>6.570703</td>\n",
       "      <td>0.447395</td>\n",
       "      <td>1.063178</td>\n",
       "      <td>1.982501</td>\n",
       "      <td>2.617110</td>\n",
       "      <td>3.335722</td>\n",
       "      <td>4.008265</td>\n",
       "      <td>4.659973</td>\n",
       "      <td>5.267832</td>\n",
       "      <td>6.166779</td>\n",
       "      <td>6.923382</td>\n",
       "      <td>7.707485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.039644</td>\n",
       "      <td>6.629376</td>\n",
       "      <td>0.447289</td>\n",
       "      <td>1.061463</td>\n",
       "      <td>1.981761</td>\n",
       "      <td>2.617614</td>\n",
       "      <td>3.334538</td>\n",
       "      <td>4.009846</td>\n",
       "      <td>4.660091</td>\n",
       "      <td>5.268501</td>\n",
       "      <td>6.169617</td>\n",
       "      <td>6.922688</td>\n",
       "      <td>7.709701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.038716</td>\n",
       "      <td>6.688550</td>\n",
       "      <td>0.447089</td>\n",
       "      <td>1.058743</td>\n",
       "      <td>1.981638</td>\n",
       "      <td>2.618797</td>\n",
       "      <td>3.332595</td>\n",
       "      <td>4.012104</td>\n",
       "      <td>4.659637</td>\n",
       "      <td>5.269165</td>\n",
       "      <td>6.172334</td>\n",
       "      <td>6.922341</td>\n",
       "      <td>7.711478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        noise  variance  lengthscale       u_1       u_2       u_3       u_4  \\\n",
       "0    1.000000  1.000000     0.500000  0.999731  1.774372  2.549012  3.323653   \n",
       "1    0.990050  1.010050     0.505025  1.009731  1.784372  2.559012  3.313653   \n",
       "2    0.980194  1.020200     0.510065  1.019704  1.794339  2.568933  3.314649   \n",
       "3    0.970430  1.030450     0.515095  1.029613  1.804274  2.578772  3.320132   \n",
       "4    0.960753  1.040801     0.520083  1.039410  1.814179  2.588522  3.327286   \n",
       "..        ...       ...          ...       ...       ...       ...       ...   \n",
       "196  0.042544  6.454843     0.447061  1.061071  1.987326  2.620075  3.333212   \n",
       "197  0.041558  6.512527     0.447141  1.061186  1.985551  2.619605  3.333238   \n",
       "198  0.040591  6.570703     0.447395  1.063178  1.982501  2.617110  3.335722   \n",
       "199  0.039644  6.629376     0.447289  1.061463  1.981761  2.617614  3.334538   \n",
       "200  0.038716  6.688550     0.447089  1.058743  1.981638  2.618797  3.332595   \n",
       "\n",
       "          u_5       u_6       u_7       u_8       u_9      u_10  \n",
       "0    4.098293  4.872934  5.647574  6.422214  7.196855  7.971495  \n",
       "1    4.108293  4.862934  5.637574  6.432214  7.186855  7.961495  \n",
       "2    4.116527  4.853544  5.627633  6.440354  7.177133  7.951505  \n",
       "3    4.121724  4.845182  5.617785  6.444156  7.167861  7.941534  \n",
       "4    4.123969  4.838044  5.608054  6.443541  7.159102  7.931596  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "196  4.010362  4.653823  5.267927  6.167223  6.917839  7.707902  \n",
       "197  4.010471  4.655941  5.268230  6.167650  6.920149  7.707936  \n",
       "198  4.008265  4.659973  5.267832  6.166779  6.923382  7.707485  \n",
       "199  4.009846  4.660091  5.268501  6.169617  6.922688  7.709701  \n",
       "200  4.012104  4.659637  5.269165  6.172334  6.922341  7.711478  \n",
       "\n",
       "[201 rows x 13 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.make_params_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FITC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sparse_GP_regression_FITC(X, y, p_optimized=True)\n",
    "mean4, cov4 = model4.predict(X_pred.clone())\n",
    "\n",
    "# visualize(X_pred, f, mean4, cov4, p_inputs=model4.pseudo_inputs, title=\"FITC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_iter: 1/200\n",
      "opt_iter: 2/200\n",
      "opt_iter: 3/200\n",
      "opt_iter: 4/200\n",
      "opt_iter: 5/200\n",
      "opt_iter: 6/200\n",
      "opt_iter: 7/200\n",
      "opt_iter: 8/200\n",
      "opt_iter: 9/200\n",
      "opt_iter: 10/200\n",
      "opt_iter: 11/200\n",
      "opt_iter: 12/200\n",
      "opt_iter: 13/200\n",
      "opt_iter: 14/200\n",
      "opt_iter: 15/200\n",
      "opt_iter: 16/200\n",
      "opt_iter: 17/200\n",
      "opt_iter: 18/200\n",
      "opt_iter: 19/200\n",
      "opt_iter: 20/200\n",
      "opt_iter: 21/200\n",
      "opt_iter: 22/200\n",
      "opt_iter: 23/200\n",
      "opt_iter: 24/200\n",
      "opt_iter: 25/200\n",
      "opt_iter: 26/200\n",
      "opt_iter: 27/200\n",
      "opt_iter: 28/200\n",
      "opt_iter: 29/200\n",
      "opt_iter: 30/200\n",
      "opt_iter: 31/200\n",
      "opt_iter: 32/200\n",
      "opt_iter: 33/200\n",
      "opt_iter: 34/200\n",
      "opt_iter: 35/200\n",
      "opt_iter: 36/200\n",
      "opt_iter: 37/200\n",
      "opt_iter: 38/200\n",
      "opt_iter: 39/200\n",
      "opt_iter: 40/200\n",
      "opt_iter: 41/200\n",
      "opt_iter: 42/200\n",
      "opt_iter: 43/200\n",
      "opt_iter: 44/200\n",
      "opt_iter: 45/200\n",
      "opt_iter: 46/200\n",
      "opt_iter: 47/200\n",
      "opt_iter: 48/200\n",
      "opt_iter: 49/200\n",
      "opt_iter: 50/200\n",
      "opt_iter: 51/200\n",
      "opt_iter: 52/200\n",
      "opt_iter: 53/200\n",
      "opt_iter: 54/200\n",
      "opt_iter: 55/200\n",
      "opt_iter: 56/200\n",
      "opt_iter: 57/200\n",
      "opt_iter: 58/200\n",
      "opt_iter: 59/200\n",
      "opt_iter: 60/200\n",
      "opt_iter: 61/200\n",
      "opt_iter: 62/200\n",
      "opt_iter: 63/200\n",
      "opt_iter: 64/200\n",
      "opt_iter: 65/200\n",
      "opt_iter: 66/200\n",
      "opt_iter: 67/200\n",
      "opt_iter: 68/200\n",
      "opt_iter: 69/200\n",
      "opt_iter: 70/200\n",
      "opt_iter: 71/200\n",
      "opt_iter: 72/200\n",
      "opt_iter: 73/200\n",
      "opt_iter: 74/200\n",
      "opt_iter: 75/200\n",
      "opt_iter: 76/200\n",
      "opt_iter: 77/200\n",
      "opt_iter: 78/200\n",
      "opt_iter: 79/200\n",
      "opt_iter: 80/200\n",
      "opt_iter: 81/200\n",
      "opt_iter: 82/200\n",
      "opt_iter: 83/200\n",
      "opt_iter: 84/200\n",
      "opt_iter: 85/200\n",
      "opt_iter: 86/200\n",
      "opt_iter: 87/200\n",
      "opt_iter: 88/200\n",
      "opt_iter: 89/200\n",
      "opt_iter: 90/200\n",
      "opt_iter: 91/200\n",
      "opt_iter: 92/200\n",
      "opt_iter: 93/200\n",
      "opt_iter: 94/200\n",
      "opt_iter: 95/200\n",
      "opt_iter: 96/200\n",
      "opt_iter: 97/200\n",
      "opt_iter: 98/200\n",
      "opt_iter: 99/200\n",
      "opt_iter: 100/200\n",
      "opt_iter: 101/200\n",
      "opt_iter: 102/200\n",
      "opt_iter: 103/200\n",
      "opt_iter: 104/200\n",
      "opt_iter: 105/200\n",
      "opt_iter: 106/200\n",
      "opt_iter: 107/200\n",
      "opt_iter: 108/200\n",
      "opt_iter: 109/200\n",
      "opt_iter: 110/200\n",
      "opt_iter: 111/200\n",
      "opt_iter: 112/200\n",
      "opt_iter: 113/200\n",
      "opt_iter: 114/200\n",
      "opt_iter: 115/200\n",
      "opt_iter: 116/200\n",
      "opt_iter: 117/200\n",
      "opt_iter: 118/200\n",
      "opt_iter: 119/200\n",
      "opt_iter: 120/200\n",
      "opt_iter: 121/200\n",
      "opt_iter: 122/200\n",
      "opt_iter: 123/200\n",
      "opt_iter: 124/200\n",
      "opt_iter: 125/200\n",
      "opt_iter: 126/200\n",
      "opt_iter: 127/200\n",
      "opt_iter: 128/200\n",
      "opt_iter: 129/200\n",
      "opt_iter: 130/200\n",
      "opt_iter: 131/200\n",
      "opt_iter: 132/200\n",
      "opt_iter: 133/200\n",
      "opt_iter: 134/200\n",
      "opt_iter: 135/200\n",
      "opt_iter: 136/200\n",
      "opt_iter: 137/200\n",
      "opt_iter: 138/200\n",
      "opt_iter: 139/200\n",
      "opt_iter: 140/200\n",
      "opt_iter: 141/200\n",
      "opt_iter: 142/200\n",
      "opt_iter: 143/200\n",
      "opt_iter: 144/200\n",
      "opt_iter: 145/200\n",
      "opt_iter: 146/200\n",
      "opt_iter: 147/200\n",
      "opt_iter: 148/200\n",
      "opt_iter: 149/200\n",
      "opt_iter: 150/200\n",
      "opt_iter: 151/200\n",
      "opt_iter: 152/200\n",
      "opt_iter: 153/200\n",
      "opt_iter: 154/200\n",
      "opt_iter: 155/200\n",
      "opt_iter: 156/200\n",
      "opt_iter: 157/200\n",
      "opt_iter: 158/200\n",
      "opt_iter: 159/200\n",
      "opt_iter: 160/200\n",
      "opt_iter: 161/200\n",
      "opt_iter: 162/200\n",
      "opt_iter: 163/200\n",
      "opt_iter: 164/200\n",
      "opt_iter: 165/200\n",
      "opt_iter: 166/200\n",
      "opt_iter: 167/200\n",
      "opt_iter: 168/200\n",
      "opt_iter: 169/200\n",
      "opt_iter: 170/200\n",
      "opt_iter: 171/200\n",
      "opt_iter: 172/200\n",
      "opt_iter: 173/200\n",
      "opt_iter: 174/200\n",
      "opt_iter: 175/200\n",
      "opt_iter: 176/200\n",
      "opt_iter: 177/200\n",
      "opt_iter: 178/200\n",
      "opt_iter: 179/200\n",
      "opt_iter: 180/200\n",
      "opt_iter: 181/200\n",
      "opt_iter: 182/200\n",
      "opt_iter: 183/200\n",
      "opt_iter: 184/200\n",
      "opt_iter: 185/200\n",
      "opt_iter: 186/200\n",
      "opt_iter: 187/200\n",
      "opt_iter: 188/200\n",
      "opt_iter: 189/200\n",
      "opt_iter: 190/200\n",
      "opt_iter: 191/200\n",
      "opt_iter: 192/200\n",
      "opt_iter: 193/200\n",
      "opt_iter: 194/200\n",
      "opt_iter: 195/200\n",
      "opt_iter: 196/200\n",
      "opt_iter: 197/200\n",
      "opt_iter: 198/200\n",
      "opt_iter: 199/200\n",
      "opt_iter: 200/200\n"
     ]
    }
   ],
   "source": [
    "model4.optimize(iteration=200, learning_rate=0.01)\n",
    "mean4_opt, cov4_opt = model4.predict(X_pred.clone())\n",
    "\n",
    "# visualize(X_pred, f, mean4_opt, cov4_opt, p_inputs=model4.pseudo_inputs, title=\"Optimized FITC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise</th>\n",
       "      <th>variance</th>\n",
       "      <th>lengthscale</th>\n",
       "      <th>u_1</th>\n",
       "      <th>u_2</th>\n",
       "      <th>u_3</th>\n",
       "      <th>u_4</th>\n",
       "      <th>u_5</th>\n",
       "      <th>u_6</th>\n",
       "      <th>u_7</th>\n",
       "      <th>u_8</th>\n",
       "      <th>u_9</th>\n",
       "      <th>u_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>1.774372</td>\n",
       "      <td>2.549012</td>\n",
       "      <td>3.323653</td>\n",
       "      <td>4.098293</td>\n",
       "      <td>4.872934</td>\n",
       "      <td>5.647574</td>\n",
       "      <td>6.422214</td>\n",
       "      <td>7.196855</td>\n",
       "      <td>7.971495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990050</td>\n",
       "      <td>1.010050</td>\n",
       "      <td>0.505025</td>\n",
       "      <td>1.009731</td>\n",
       "      <td>1.784372</td>\n",
       "      <td>2.559012</td>\n",
       "      <td>3.313653</td>\n",
       "      <td>4.108293</td>\n",
       "      <td>4.862934</td>\n",
       "      <td>5.637574</td>\n",
       "      <td>6.432214</td>\n",
       "      <td>7.186855</td>\n",
       "      <td>7.961495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980194</td>\n",
       "      <td>1.020200</td>\n",
       "      <td>0.510065</td>\n",
       "      <td>1.019704</td>\n",
       "      <td>1.794339</td>\n",
       "      <td>2.568933</td>\n",
       "      <td>3.314649</td>\n",
       "      <td>4.116527</td>\n",
       "      <td>4.853544</td>\n",
       "      <td>5.627633</td>\n",
       "      <td>6.440354</td>\n",
       "      <td>7.177133</td>\n",
       "      <td>7.951505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970430</td>\n",
       "      <td>1.030450</td>\n",
       "      <td>0.515095</td>\n",
       "      <td>1.029613</td>\n",
       "      <td>1.804274</td>\n",
       "      <td>2.578772</td>\n",
       "      <td>3.320132</td>\n",
       "      <td>4.121724</td>\n",
       "      <td>4.845182</td>\n",
       "      <td>5.617785</td>\n",
       "      <td>6.444156</td>\n",
       "      <td>7.167861</td>\n",
       "      <td>7.941534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.960753</td>\n",
       "      <td>1.040801</td>\n",
       "      <td>0.520083</td>\n",
       "      <td>1.039410</td>\n",
       "      <td>1.814179</td>\n",
       "      <td>2.588522</td>\n",
       "      <td>3.327286</td>\n",
       "      <td>4.123969</td>\n",
       "      <td>4.838044</td>\n",
       "      <td>5.608054</td>\n",
       "      <td>6.443541</td>\n",
       "      <td>7.159102</td>\n",
       "      <td>7.931596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.042544</td>\n",
       "      <td>6.454843</td>\n",
       "      <td>0.447061</td>\n",
       "      <td>1.061071</td>\n",
       "      <td>1.987326</td>\n",
       "      <td>2.620075</td>\n",
       "      <td>3.333212</td>\n",
       "      <td>4.010362</td>\n",
       "      <td>4.653823</td>\n",
       "      <td>5.267927</td>\n",
       "      <td>6.167223</td>\n",
       "      <td>6.917839</td>\n",
       "      <td>7.707902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.041558</td>\n",
       "      <td>6.512527</td>\n",
       "      <td>0.447141</td>\n",
       "      <td>1.061186</td>\n",
       "      <td>1.985551</td>\n",
       "      <td>2.619605</td>\n",
       "      <td>3.333238</td>\n",
       "      <td>4.010471</td>\n",
       "      <td>4.655941</td>\n",
       "      <td>5.268230</td>\n",
       "      <td>6.167650</td>\n",
       "      <td>6.920149</td>\n",
       "      <td>7.707936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.040591</td>\n",
       "      <td>6.570703</td>\n",
       "      <td>0.447395</td>\n",
       "      <td>1.063178</td>\n",
       "      <td>1.982501</td>\n",
       "      <td>2.617110</td>\n",
       "      <td>3.335722</td>\n",
       "      <td>4.008265</td>\n",
       "      <td>4.659973</td>\n",
       "      <td>5.267832</td>\n",
       "      <td>6.166779</td>\n",
       "      <td>6.923382</td>\n",
       "      <td>7.707485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.039644</td>\n",
       "      <td>6.629376</td>\n",
       "      <td>0.447289</td>\n",
       "      <td>1.061463</td>\n",
       "      <td>1.981761</td>\n",
       "      <td>2.617614</td>\n",
       "      <td>3.334538</td>\n",
       "      <td>4.009846</td>\n",
       "      <td>4.660091</td>\n",
       "      <td>5.268501</td>\n",
       "      <td>6.169617</td>\n",
       "      <td>6.922688</td>\n",
       "      <td>7.709701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.038716</td>\n",
       "      <td>6.688550</td>\n",
       "      <td>0.447089</td>\n",
       "      <td>1.058743</td>\n",
       "      <td>1.981638</td>\n",
       "      <td>2.618797</td>\n",
       "      <td>3.332595</td>\n",
       "      <td>4.012104</td>\n",
       "      <td>4.659637</td>\n",
       "      <td>5.269165</td>\n",
       "      <td>6.172334</td>\n",
       "      <td>6.922341</td>\n",
       "      <td>7.711478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        noise  variance  lengthscale       u_1       u_2       u_3       u_4  \\\n",
       "0    1.000000  1.000000     0.500000  0.999731  1.774372  2.549012  3.323653   \n",
       "1    0.990050  1.010050     0.505025  1.009731  1.784372  2.559012  3.313653   \n",
       "2    0.980194  1.020200     0.510065  1.019704  1.794339  2.568933  3.314649   \n",
       "3    0.970430  1.030450     0.515095  1.029613  1.804274  2.578772  3.320132   \n",
       "4    0.960753  1.040801     0.520083  1.039410  1.814179  2.588522  3.327286   \n",
       "..        ...       ...          ...       ...       ...       ...       ...   \n",
       "196  0.042544  6.454843     0.447061  1.061071  1.987326  2.620075  3.333212   \n",
       "197  0.041558  6.512527     0.447141  1.061186  1.985551  2.619605  3.333238   \n",
       "198  0.040591  6.570703     0.447395  1.063178  1.982501  2.617110  3.335722   \n",
       "199  0.039644  6.629376     0.447289  1.061463  1.981761  2.617614  3.334538   \n",
       "200  0.038716  6.688550     0.447089  1.058743  1.981638  2.618797  3.332595   \n",
       "\n",
       "          u_5       u_6       u_7       u_8       u_9      u_10  \n",
       "0    4.098293  4.872934  5.647574  6.422214  7.196855  7.971495  \n",
       "1    4.108293  4.862934  5.637574  6.432214  7.186855  7.961495  \n",
       "2    4.116527  4.853544  5.627633  6.440354  7.177133  7.951505  \n",
       "3    4.121724  4.845182  5.617785  6.444156  7.167861  7.941534  \n",
       "4    4.123969  4.838044  5.608054  6.443541  7.159102  7.931596  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "196  4.010362  4.653823  5.267927  6.167223  6.917839  7.707902  \n",
       "197  4.010471  4.655941  5.268230  6.167650  6.920149  7.707936  \n",
       "198  4.008265  4.659973  5.267832  6.166779  6.923382  7.707485  \n",
       "199  4.009846  4.660091  5.268501  6.169617  6.922688  7.709701  \n",
       "200  4.012104  4.659637  5.269165  6.172334  6.922341  7.711478  \n",
       "\n",
       "[201 rows x 13 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.make_params_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
